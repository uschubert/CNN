{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras.utils\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data:\n",
    "Using ShowJetsData_full.npz to build the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 16\n",
    "data= np.load('data/ShowJetsData_full.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 103. MiB for an array with shape (13449124,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce7b684100b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Sum all signal labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ce7b684100b8>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Sum all signal labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/LRP/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/LRP/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 103. MiB for an array with shape (13449124,) and data type float64"
     ]
    }
   ],
   "source": [
    "data_dic={key : data[key]  for key in data.keys()}\n",
    "n_data=len(data_dic['labels'])\n",
    "# Sum all signal labels\n",
    "data_dic['labels']=np.array([[ele[0],np.sum(ele[1:])] for ele in data_dic['labels']]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance and Normalize data and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build list of signal and background indices, balance them, shuffle and combine back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "ind_sig_inb=np.argwhere(data_dic['labels'][:,1]==1)[:,0]\n",
    "ind_bkg=np.argwhere(data_dic['labels'][:,0]==1)[:,0]\n",
    "ind_sig=random.choices(ind_sig_inb,k=len(ind_bkg))\n",
    "ind=np.concatenate((ind_bkg,ind_sig),axis=0)\n",
    "np.random.shuffle(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ind_bkg))\n",
    "print(len(ind_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build two dictionaries with train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train={}\n",
    "data_test={}\n",
    "cut=int(split*len(ind))\n",
    "for key in data_dic.keys():\n",
    "    sub=data_dic[key][ind]\n",
    "    if key=='jetImages':\n",
    "        minn=np.min(sub)\n",
    "        maxx=np.max(sub)\n",
    "        data_train[key]=(sub[:cut]-minn)/(maxx-minn)\n",
    "        data_test[key]=(sub[cut:]-minn)/(maxx-minn)\n",
    "    else:\n",
    "        minn=np.min(sub,axis=0)\n",
    "        maxx=np.max(sub,axis=0)\n",
    "        data_train[key]=(sub[:cut]-minn)/(maxx-minn)\n",
    "        data_test[key]=(sub[cut:]-minn)/(maxx-minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=len(data_train['jetPt'])\n",
    "print(n_train)\n",
    "n_test=len(data_test['jetPt'])\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in data_dic.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features will be loaded into X\n",
    "features=['jetImages','jetPt','jetEta','jetPhi','tau21','chMult','neutMult','phoMult','eleMult','muMult','jetpull']\n",
    "# label into Y\n",
    "label=['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[data_train[key] for key in features]\n",
    "X_test=[data_test[key] for key in features]\n",
    "Y_train=[data_train[key] for key in label]\n",
    "Y_test=[data_test[key] for key in label]\n",
    "# Reshape pictures for CNN\n",
    "X_train[0]=X_train[0].reshape(n_train, grid, grid, 1)\n",
    "X_test[0]=X_test[0].reshape(n_test, grid, grid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=[1 if ele[0].shape==() else ele[0].shape[0] for ele in X_train]\n",
    "for i in range(1,len(X_train)):\n",
    "    X_train[i]=X_train[i].reshape(len(X_train[i]),dim[i])\n",
    "for i in range(1,len(X_test)):\n",
    "    X_test[i]=X_test[i].reshape(len(X_test[i]),dim[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls training\n",
    "best_model = keras.models.load_model('model/CNN_full.h1')\n",
    "best_model.summary()\n",
    "results = best_model.evaluate(X_test, Y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test[0][:,1], predict[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, color='b', label='auc = %.3f' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('receiver operating curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.utils as iutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lrp():\n",
    "    input1 = layers.Input(shape = (2058,))\n",
    "    x = layers.Dense(256, activation='relu')(input1)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    model = models.Model(inputs=input1, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring layer -1\n",
      "Transferring layer -2\n",
      "Transferring layer -3\n"
     ]
    }
   ],
   "source": [
    "# Split Model into Convolutional and dense part \n",
    "conv_model=models.Model(best_model.input,best_model.layers[-3].output)\n",
    "dense_model = build_model_lrp()\n",
    "for i in range(-1,-4,-1):\n",
    "    print('Transferring layer',i)\n",
    "    weight=best_model.layers[i].get_weights()\n",
    "    dense_model.layers[i].set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test=len(X_test[1])\n",
    "# Reshape tensors for LRP\n",
    "# note all inputs that have dim>1 have to reshaped to (1,dim)\n",
    "X_lrp=[[X_test[i][j] for i in range(len(features))] for j in range(n_test)]\n",
    "for i in range(n_test):\n",
    "    X_lrp[i][0]=X_lrp[i][0].reshape(1,grid,grid,1)\n",
    "#    X_lrp[i][1]=X_lrp[i][1].reshape(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build intermediate input for dense layers\n",
    "X_dense=[conv_model.predict(X_lrp[i]) for i in range(n_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23649888 0.7635011 ]]\n",
      "[[0.23649888 0.7635011 ]]\n"
     ]
    }
   ],
   "source": [
    "# Our divided model and full model give same output\n",
    "print(dense_model.predict(X_dense[0]))\n",
    "print(best_model.predict(X_lrp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel_ws = iutils.keras.graph.model_wo_softmax(best_model)\n",
    "dmodel_ws = iutils.keras.graph.model_wo_softmax(dense_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LRP on Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Image (pick some number from 0 to 19999)\n",
    "imgnum=1\n",
    "# Creating an analyzer\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.z\", bmodel_ws)\n",
    "lrp_analyzer = innvestigate.create_analyzer(\"lrp.z_IB\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.epsilon\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.epsilon_IB\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_2_beta_1\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_2_beta_1_IB\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_1_beta_0\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_1_beta_0_IB\", bmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.w_square\", bmodel_ws)\n",
    "# Applying the analyzer\n",
    "analysis1 = lrp_analyzer.analyze(X_lrp[imgnum])\n",
    "# # Displaying one result\n",
    "# plt.imshow(analysis[0].reshape(grid, grid), cmap='RdBu', origin = 'low', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.clim(-0.6, 0.6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.          151.38747     -36.839973      0.45340058 -304.22818\n",
      "   96.427055     28.651556     76.41347       0.            0.\n",
      "  -11.26477   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0000315"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[np.sum(ele) for ele in analysis1]/np.max(bmodel_ws.predict(X_lrp[imgnum])[0])\n",
    "print(test)\n",
    "np.sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " time = \n",
      " 169.76690983772278\n"
     ]
    }
   ],
   "source": [
    "#plot output signal and background\n",
    "toc = time.time()\n",
    "\n",
    "display = X_lrp\n",
    "analysis = [lrp_analyzer.analyze(display[i]) for i in range(n_test)]\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print('\\n time = \\n', tic-toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_sum=np.array([[np.sum(ele) for ele in ana] for ana in analysis])\n",
    "model_out=np.max(bmodel_ws.predict(X_test),axis=1)\n",
    "# for i in range(n_test):\n",
    "#     ana_sum[i]=ana_sum[i]/model_out[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.z\n",
    "# w bias\n",
    "#[0,0.15245031,-0.03593288,0.05130995,-0.04468057,0.2581704,0.2087618,0.1450953,-0.17734969,0.01397072,0.11162304]\n",
    "# w/o bias\n",
    "#[0.,9.520095,-2.535502,-0.88078153,-12.137775,3.0656643,0.49566087,3.0224466,0.6144052,-0.02010816,-0.14410827]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.eps\n",
    "# w bias\n",
    "#[0,0.14857137,-0.03649887,0.05139174,-0.02610694,0.25736007,0.20831804,0.1450683,-0.17557515,0.01397153,0.11133406]\n",
    "# w/o bias\n",
    "#[0,8.182605,-2.3030596,-0.6515178,-11.467334,3.2472591,0.57624966,3.1228225,0.414409,-0.01806587,-0.10341328]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lrp.alpha_2_beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ana_sum,axis=0) # This was with lrp.alpha beta\n",
    "# w bias\n",
    "#\n",
    "# w/o bias\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.alpha_1_beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp. alpha beta\n",
    "# w bias\n",
    "#\n",
    "# w/o bias\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lrp.w_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.z\n",
    "# w bias\n",
    "#\n",
    "# w/o bias\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Only Dense Layers with LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Image (pick some number from 0 to 19999)\n",
    "imgnum=0\n",
    "# Creating an analyzer\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.z\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.z_IB\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.epsilon\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.epsilon_IB\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_2_beta_1\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_2_beta_1_IB\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_1_beta_0\", dmodel_ws)\n",
    "#lrp_analyzer = innvestigate.create_analyzer(\"lrp.alpha_1_beta_0_IB\", dmodel_ws)\n",
    "lrp_analyzer = innvestigate.create_analyzer(\"lrp.w_square\", dmodel_ws)\n",
    "# Applying the analyzer\n",
    "analysis = lrp_analyzer.analyze(X_dense[imgnum])\n",
    "# # Displaying one result\n",
    "# plt.imshow(analysis[0].reshape(grid, grid), cmap='RdBu', origin = 'low', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.clim(-0.6, 0.6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.3649610e-01, 2.7217567e-01, 2.0156763e-03, 1.1242766e-04,\n",
       "       4.4729367e-02, 5.0941583e-02, 8.8997893e-03, 2.3588330e-02,\n",
       "       1.1652018e-02, 4.8812993e-02, 5.7618663e-04], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum(analysis[0][:2048]),analysis[0][2048],analysis[0][2049],analysis[0][2050],analysis[0][2051],analysis[0][2052],analysis[0][2053],analysis[0][2054],analysis[0][2055],analysis[0][2056],analysis[0][2057]]/np.max(dmodel_ws.predict(X_dense[imgnum])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " time = \n",
      " 80.83300423622131\n"
     ]
    }
   ],
   "source": [
    "#plot output signal and background\n",
    "toc = time.time()\n",
    "\n",
    "analysis = [lrp_analyzer.analyze(X_dense[i]) for i in range(n_test)]\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print('\\n time = \\n', tic-toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_sum=np.array([[np.sum(ana[0][:2048]),ana[0][2048],ana[0][2049],ana[0][2050],ana[0][2051],ana[0][2052],ana[0][2053],ana[0][2054],ana[0][2055],ana[0][2056],ana[0][2057]] for ana in analysis])\n",
    "model_out=[np.max(dmodel_ws.predict(X_dense[i]),axis=1) for i in range(n_test)]\n",
    "for i in range(n_test):\n",
    "    ana_sum[i]=ana_sum[i]/model_out[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.z\n",
    "# w bias\n",
    "#[0,0.15245031,-0.03593288,0.05130995,-0.04468057,0.2581704,0.2087618,0.1450953,-0.17734969,0.01397072,0.11162304]\n",
    "# w/o bias\n",
    "#[0.,9.520095,-2.535502,-0.88078153,-12.137775,3.0656643,0.49566087,3.0224466,0.6144052,-0.02010816,-0.14410827]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.eps\n",
    "# w bias\n",
    "#[0,0.14857137,-0.03649887,0.05139174,-0.02610694,0.25736007,0.20831804,0.1450683,-0.17557515,0.01397153,0.11133406]\n",
    "# w/o bias\n",
    "#[0,8.182605,-2.3030596,-0.6515178,-11.467334,3.2472591,0.57624966,3.1228225,0.414409,-0.01806587,-0.10341328]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lrp.alpha_2_beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.alpha beta\n",
    "# w bias\n",
    "#[0,-0.01390401,-0.08162314,-0.04154111,-2.587854,-0.89187473,-0.29644567,-0.7046687,0.0259149,0.0827094,-0.12362336]\n",
    "# w/o bias\n",
    "#[0,0.2162189,-0.2908635,0.01094637,0.1206545,0.40172812,0.09193143,0.46828508,0.01128768,0.01890007,-0.04908316]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP.alpha_1_beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp. alpha beta\n",
    "# w bias\n",
    "#[0,0.13975509,0.05845137,0.02391208,0.35817838,0.17191088,0.04670334,0.1603134,0.0109716,0.00353415,0.04965757]\n",
    "# w/o bias\n",
    "#[0,0.18698053,0.09168747,0.0317525,0.19809927,0.19378904,0.0452356,0.19756816,0.00735529,0.00591376,0.04160213]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lrp.w_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(ana_sum,axis=0) # This was with lrp.w_square\n",
    "# w/o bias\n",
    "# [0.53547615,0.27360874,0.0020234047,0.00011119822,0.044179935,0.051342096,0.0090042530,0.023703365,0.011661683,0.048817620,0.00056479638]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
